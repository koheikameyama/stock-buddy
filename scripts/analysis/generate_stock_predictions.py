#!/usr/bin/env python3
"""
éŠ˜æŸ„å‹•å‘äºˆæ¸¬ç”Ÿæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹åˆ†æž + AIäºˆæ¸¬ã®ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ–¹å¼ã§ã€
å„éŠ˜æŸ„ã®çŸ­æœŸãƒ»ä¸­æœŸãƒ»é•·æœŸã®è¦‹é€šã—ã¨ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’ç”Ÿæˆã—ã¾ã™ã€‚
"""

import os
import sys
import json
import psycopg2
import psycopg2.extras
from openai import OpenAI
from datetime import datetime
import statistics

# Add news fetcher module
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))
from lib.news_fetcher import get_related_news, format_news_for_prompt

DATABASE_URL = os.getenv("DATABASE_URL")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

client = OpenAI(api_key=OPENAI_API_KEY)


def calculate_trend(current, past):
    """ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’è¨ˆç®—"""
    if not past:
        return "neutral"

    change = ((current - past) / past) * 100

    if change > 2:
        return "up"
    elif change < -2:
        return "down"
    else:
        return "neutral"


def calculate_volatility(prices):
    """ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆæ¨™æº–åå·®ï¼‰ã‚’è¨ˆç®—"""
    if len(prices) < 2:
        return 0.0
    return statistics.stdev(prices)


def get_baseline_data(cur, stock_id):
    """ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã§åŸºç¤Žãƒ‡ãƒ¼ã‚¿ã‚’è¨ˆç®—"""

    # éŽåŽ»90æ—¥åˆ†ã®ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    cur.execute(
        """
        SELECT close, date
        FROM "StockPrice"
        WHERE "stockId" = %s
        ORDER BY date DESC
        LIMIT 90
    """,
        (stock_id,),
    )

    price_history = cur.fetchall()

    if not price_history:
        return None

    current_price = float(price_history[0][0])
    week_ago = float(price_history[5][0]) if len(price_history) > 5 else None
    month_ago = float(price_history[20][0]) if len(price_history) > 20 else None
    three_months_ago = (
        float(price_history[60][0]) if len(price_history) > 60 else None
    )

    # ãƒˆãƒ¬ãƒ³ãƒ‰è¨ˆç®—
    weekly_trend = calculate_trend(current_price, week_ago)
    monthly_trend = calculate_trend(current_price, month_ago)
    quarterly_trend = calculate_trend(current_price, three_months_ago)

    # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£è¨ˆç®—ï¼ˆç›´è¿‘30æ—¥ï¼‰
    prices = [float(p[0]) for p in price_history[:30]]
    volatility = calculate_volatility(prices)

    return {
        "current_price": current_price,
        "weekly_trend": weekly_trend,
        "monthly_trend": monthly_trend,
        "quarterly_trend": quarterly_trend,
        "volatility": volatility,
    }


def generate_ai_prediction(stock, baseline, scores, related_news=None):
    """AIã§äºˆæ¸¬ã‚’ç”Ÿæˆ"""

    trend_labels = {"up": "ä¸Šæ˜‡", "neutral": "æ¨ªã°ã„", "down": "ä¸‹é™"}

    # ãƒ‹ãƒ¥ãƒ¼ã‚¹æƒ…å ±ã‚’ãƒ•ã‚©ãƒ¼ãƒžãƒƒãƒˆ
    news_context = ""
    if related_news:
        news_context = f"""

ã€æœ€æ–°ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹æƒ…å ±ã€‘
{format_news_for_prompt(related_news)}
"""

    prompt = f"""ã‚ãªãŸã¯æ ªå¼æŠ•è³‡ã®åˆå¿ƒè€…å‘ã‘ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼ã§ã™ã€‚
ä»¥ä¸‹ã®éŠ˜æŸ„ã«ã¤ã„ã¦ã€ä»Šå¾Œã®å‹•å‘äºˆæ¸¬ã¨ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

ã€éŠ˜æŸ„æƒ…å ±ã€‘
åç§°: {stock['name']}
ãƒ†ã‚£ãƒƒã‚«ãƒ¼: {stock['ticker_code']}
ã‚»ã‚¯ã‚¿ãƒ¼: {stock['sector'] or 'ä¸æ˜Ž'}
ç¾åœ¨ä¾¡æ ¼: {baseline['current_price']:.2f}å††

ã€éŽåŽ»ã®ãƒˆãƒ¬ãƒ³ãƒ‰ã€‘
- 1é€±é–“: {trend_labels[baseline['weekly_trend']]}
- 1ãƒ¶æœˆ: {trend_labels[baseline['monthly_trend']]}
- 3ãƒ¶æœˆ: {trend_labels[baseline['quarterly_trend']]}

ã€ã‚¹ã‚³ã‚¢ã€‘
- æˆé•·æ€§: {scores['growth']}/100
- å®‰å®šæ€§: {scores['stability']}/100
- é…å½“æ€§: {scores['dividend']}/100

ã€ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆä¾¡æ ¼å¤‰å‹•å¹…ï¼‰ã€‘
{baseline['volatility']:.2f}å††
{news_context}
---

ä»¥ä¸‹ã®å½¢å¼ã§JSONå½¢å¼ã§å›žç­”ã—ã¦ãã ã•ã„ï¼š

{{
  "shortTerm": {{
    "trend": "up" | "neutral" | "down",
    "priceLow": æ•°å€¤,
    "priceHigh": æ•°å€¤
  }},
  "midTerm": {{
    "trend": "up" | "neutral" | "down",
    "priceLow": æ•°å€¤,
    "priceHigh": æ•°å€¤
  }},
  "longTerm": {{
    "trend": "up" | "neutral" | "down",
    "priceLow": æ•°å€¤,
    "priceHigh": æ•°å€¤
  }},
  "recommendation": "buy" | "hold" | "sell",
  "advice": "åˆå¿ƒè€…å‘ã‘ã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹ï¼ˆ100æ–‡å­—ä»¥å†…ã€å„ªã—ã„è¨€è‘‰ã§ã€ãƒ‹ãƒ¥ãƒ¼ã‚¹æƒ…å ±ãŒã‚ã‚Œã°å‚è€ƒã«ã™ã‚‹ï¼‰",
  "confidence": 0.0ã€œ1.0ã®ä¿¡é ¼åº¦
}}

æ³¨æ„äº‹é …:
- æä¾›ã•ã‚ŒãŸãƒ‹ãƒ¥ãƒ¼ã‚¹æƒ…å ±ã‚’å‚è€ƒã«ã—ã¦ãã ã•ã„
- ãƒ‹ãƒ¥ãƒ¼ã‚¹ã«ãªã„æƒ…å ±ã¯æŽ¨æ¸¬ã‚„å‰µä½œã‚’ã—ãªã„ã§ãã ã•ã„
- ä¾¡æ ¼äºˆæ¸¬ã¯ç¾åœ¨ä¾¡æ ¼ã¨ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚’è€ƒæ…®ã—ãŸç¾å®Ÿçš„ãªç¯„å›²ã«ã™ã‚‹
- ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã¯å…·ä½“çš„ã§åˆ†ã‹ã‚Šã‚„ã™ã
- æ–­å®šçš„ãªè¡¨ç¾ã¯é¿ã‘ã€ã€Œã€œãŒæœŸå¾…ã§ãã¾ã™ã€ã€Œã€œã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€ãªã©æŸ”ã‚‰ã‹ã„è¡¨ç¾ã‚’ä½¿ã†
- æŠ•è³‡åˆ¤æ–­ã¯æœ€çµ‚çš„ã«ãƒ¦ãƒ¼ã‚¶ãƒ¼è‡ªèº«ãŒè¡Œã†ã“ã¨ã‚’å‰æã«ã™ã‚‹
"""

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        response_format={"type": "json_object"},
        temperature=0.7,
    )

    prediction = json.loads(response.choices[0].message.content)
    return prediction


def save_prediction(cur, stock_id, prediction):
    """äºˆæ¸¬ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜"""

    cur.execute(
        """
        INSERT INTO "StockAnalysis" (
            id, "stockId",
            "shortTermTrend", "shortTermPriceLow", "shortTermPriceHigh",
            "midTermTrend", "midTermPriceLow", "midTermPriceHigh",
            "longTermTrend", "longTermPriceLow", "longTermPriceHigh",
            recommendation, advice, confidence,
            "analyzedAt", "createdAt"
        )
        VALUES (
            gen_random_uuid(), %s,
            %s, %s, %s,
            %s, %s, %s,
            %s, %s, %s,
            %s, %s, %s,
            NOW(), NOW()
        )
    """,
        (
            stock_id,
            prediction["shortTerm"]["trend"],
            prediction["shortTerm"]["priceLow"],
            prediction["shortTerm"]["priceHigh"],
            prediction["midTerm"]["trend"],
            prediction["midTerm"]["priceLow"],
            prediction["midTerm"]["priceHigh"],
            prediction["longTerm"]["trend"],
            prediction["longTerm"]["priceLow"],
            prediction["longTerm"]["priceHigh"],
            prediction["recommendation"],
            prediction["advice"],
            prediction["confidence"],
        ),
    )


def main():
    print("ðŸš€ Starting stock predictions generation...")

    if not DATABASE_URL:
        print("âŒ ERROR: DATABASE_URL not set")
        sys.exit(1)

    if not OPENAI_API_KEY:
        print("âŒ ERROR: OPENAI_API_KEY not set")
        sys.exit(1)

    conn = psycopg2.connect(DATABASE_URL)
    cur = conn.cursor(cursor_factory=psycopg2.extras.DictCursor)

    try:
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒä¿æœ‰/ã‚¦ã‚©ãƒƒãƒã—ã¦ã„ã‚‹éŠ˜æŸ„ã‚’å–å¾—
        cur.execute(
            """
            SELECT DISTINCT s.id, s."tickerCode", s.name, s.sector,
                   s."growthScore", s."stabilityScore", s."dividendScore"
            FROM "Stock" s
            WHERE s.id IN (
                SELECT "stockId" FROM "PortfolioStock"
                UNION
                SELECT "stockId" FROM "WatchlistStock"
            )
        """
        )

        stocks = cur.fetchall()
        total = len(stocks)

        if total == 0:
            print("âš ï¸  No stocks to analyze")
            return

        print(f"ðŸ“Š Processing {total} stocks...")

        # é–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’ä¸€æ‹¬å–å¾—
        ticker_codes = [s["tickerCode"] for s in stocks]
        sectors = list(set([s["sector"] for s in stocks if s["sector"]]))

        print(f"ðŸ“° Fetching related news for {len(ticker_codes)} stocks...")
        all_news = get_related_news(
            conn=conn,
            ticker_codes=ticker_codes,
            sectors=sectors,
            limit=30,  # äºˆæ¸¬ç”Ÿæˆã¯å¤šã‚ã«å–å¾—
            days_ago=7,
        )
        print(f"Found {len(all_news)} related news articles")

        success = 0
        failed = 0

        for i, stock in enumerate(stocks, 1):
            stock_dict = {
                "id": stock["id"],
                "ticker_code": stock["tickerCode"],
                "name": stock["name"],
                "sector": stock["sector"],
            }

            scores = {
                "growth": stock["growthScore"] or 50,
                "stability": stock["stabilityScore"] or 50,
                "dividend": stock["dividendScore"] or 50,
            }

            try:
                print(
                    f"[{i}/{total}] Processing {stock_dict['name']} ({stock_dict['ticker_code']})..."
                )

                # ã“ã®éŠ˜æŸ„ã«é–¢é€£ã™ã‚‹ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                stock_news = [
                    n for n in all_news
                    if (stock_dict['ticker_code'] in n['content'] or
                        stock_dict['ticker_code'].replace('.T', '') in n['content'] or
                        n['sector'] == stock_dict['sector'])
                ][:5]  # æœ€å¤§5ä»¶

                print(f"  ðŸ“° Found {len(stock_news)} news for this stock")

                # 1. åŸºç¤Žãƒ‡ãƒ¼ã‚¿è¨ˆç®—
                baseline = get_baseline_data(cur, stock_dict["id"])

                if not baseline:
                    print(f"  âš ï¸  No price data available, skipping...")
                    failed += 1
                    continue

                # 2. AIäºˆæ¸¬ç”Ÿæˆï¼ˆãƒ‹ãƒ¥ãƒ¼ã‚¹ä»˜ãï¼‰
                prediction = generate_ai_prediction(stock_dict, baseline, scores, stock_news)

                # 3. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
                save_prediction(cur, stock_dict["id"], prediction)

                conn.commit()
                success += 1
                print(f"  âœ… Saved (recommendation: {prediction['recommendation']})")

            except Exception as e:
                print(f"  âŒ Error: {e}")
                conn.rollback()
                failed += 1

        print(f"\nðŸŽ‰ Completed!")
        print(f"  âœ… Success: {success}")
        print(f"  âŒ Failed: {failed}")
        print(f"  ðŸ“Š Total: {total}")

        if failed > 0 and success == 0:
            sys.exit(1)

    finally:
        cur.close()
        conn.close()


if __name__ == "__main__":
    main()
