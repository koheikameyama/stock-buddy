# News RAG Integration for Python Analysis Scripts Implementation Plan

> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.

**Goal:** Integrate MarketNews data into Python analysis scripts (purchase recommendations, portfolio analysis, and stock predictions) to provide AI with latest news context.

**Architecture:** Add shared news fetching function in Python, query MarketNews table with hybrid search (ticker code â†’ sector fallback), format news for AI prompts, and include news references in analysis results.

**Tech Stack:** Python 3, psycopg2, PostgreSQL, OpenAI API (gpt-4o-mini)

---

## Task 1: Create Shared News Fetching Module

**Files:**
- Create: `scripts/lib/news_fetcher.py`

**Step 1: Create lib directory structure**

```bash
mkdir -p scripts/lib
touch scripts/lib/__init__.py
```

**Step 2: Write news fetching function**

Create `scripts/lib/news_fetcher.py`:

```python
#!/usr/bin/env python3
"""
ãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾—ã®å…±é€šãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

MarketNewsãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰é–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å–å¾—ã™ã‚‹
"""

import psycopg2
import psycopg2.extras
from datetime import datetime, timedelta, timezone
from typing import List, Optional, Dict, Any


def get_related_news(
    conn: psycopg2.extensions.connection,
    ticker_codes: Optional[List[str]] = None,
    sectors: Optional[List[str]] = None,
    limit: int = 10,
    days_ago: int = 7,
) -> List[Dict[str, Any]]:
    """
    é–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å–å¾—ã™ã‚‹ï¼ˆãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ï¼‰

    å„ªå…ˆåº¦:
    1. éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰æ¤œç´¢ï¼ˆcontent LIKE '%7203%'ï¼‰
    2. ã‚»ã‚¯ã‚¿ãƒ¼æ¤œç´¢ï¼ˆsector IN (...)ï¼‰

    Args:
        conn: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š
        ticker_codes: éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰é…åˆ—ï¼ˆä¾‹ï¼š["7203.T", "6758.T"]ï¼‰
        sectors: ã‚»ã‚¯ã‚¿ãƒ¼é…åˆ—ï¼ˆä¾‹ï¼š["è‡ªå‹•è»Š", "ITãƒ»ã‚µãƒ¼ãƒ“ã‚¹"]ï¼‰
        limit: å–å¾—ä»¶æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 10ï¼‰
        days_ago: ä½•æ—¥å‰ã¾ã§ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 7ï¼‰

    Returns:
        ãƒ‹ãƒ¥ãƒ¼ã‚¹é…åˆ—
    """
    cur = conn.cursor(cursor_factory=psycopg2.extras.RealDictCursor)

    try:
        cutoff_date = datetime.now(timezone.utc) - timedelta(days=days_ago)
        news_map = {}  # é‡è¤‡æ’é™¤ç”¨

        # ã‚¹ãƒ†ãƒƒãƒ—1: éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰æ¤œç´¢ï¼ˆå„ªå…ˆï¼‰
        if ticker_codes:
            for ticker_code in ticker_codes:
                # .Tã‚µãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’é™¤å»ã—ã¦æ¤œç´¢
                code_without_suffix = ticker_code.replace(".T", "")

                cur.execute(
                    """
                    SELECT
                        id,
                        title,
                        content,
                        url,
                        source,
                        sector,
                        sentiment,
                        "publishedAt"
                    FROM "MarketNews"
                    WHERE (
                        content LIKE %s OR content LIKE %s
                    )
                    AND "publishedAt" >= %s
                    ORDER BY "publishedAt" DESC
                    LIMIT %s
                    """,
                    (
                        f"%{code_without_suffix}%",
                        f"%{ticker_code}%",
                        cutoff_date,
                        limit,
                    ),
                )

                for row in cur.fetchall():
                    if row["id"] not in news_map:
                        news_map[row["id"]] = dict(row)
                        news_map[row["id"]]["match_type"] = "ticker"

        # ã‚¹ãƒ†ãƒƒãƒ—2: ã‚»ã‚¯ã‚¿ãƒ¼æ¤œç´¢ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
        if len(news_map) < limit and sectors:
            remaining_limit = limit - len(news_map)
            existing_ids = list(news_map.keys())

            placeholders = ",".join(["%s"] * len(sectors))
            query = f"""
                SELECT
                    id,
                    title,
                    content,
                    url,
                    source,
                    sector,
                    sentiment,
                    "publishedAt"
                FROM "MarketNews"
                WHERE sector IN ({placeholders})
                AND "publishedAt" >= %s
                {"AND id NOT IN (" + ",".join(["%s"] * len(existing_ids)) + ")" if existing_ids else ""}
                ORDER BY "publishedAt" DESC
                LIMIT %s
            """

            params = list(sectors) + [cutoff_date]
            if existing_ids:
                params.extend(existing_ids)
            params.append(remaining_limit)

            cur.execute(query, params)

            for row in cur.fetchall():
                if row["id"] not in news_map:
                    news_map[row["id"]] = dict(row)
                    news_map[row["id"]]["match_type"] = "sector"

        # æ—¥ä»˜é †ã«ã‚½ãƒ¼ãƒˆ
        result = sorted(
            news_map.values(),
            key=lambda x: x["publishedAt"],
            reverse=True,
        )

        return result[:limit]

    except Exception as e:
        print(f"Error fetching related news: {e}")
        # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ç©ºé…åˆ—ã‚’è¿”ã™ï¼ˆåˆ†æã¯ç¶™ç¶šå¯èƒ½ï¼‰
        return []
    finally:
        cur.close()


def format_news_for_prompt(news: List[Dict[str, Any]]) -> str:
    """
    ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”¨ã«ãƒ‹ãƒ¥ãƒ¼ã‚¹æƒ…å ±ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã™ã‚‹

    Args:
        news: ãƒ‹ãƒ¥ãƒ¼ã‚¹é…åˆ—

    Returns:
        ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¸ˆã¿ãƒ‹ãƒ¥ãƒ¼ã‚¹æ–‡å­—åˆ—
    """
    if not news:
        return "ï¼ˆæœ€æ–°ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹æƒ…å ±ã¯ã‚ã‚Šã¾ã›ã‚“ï¼‰"

    lines = []
    for n in news:
        published = n["publishedAt"]
        date_str = published.strftime("%Y-%m-%d") if hasattr(published, "strftime") else str(published)[:10]

        content_preview = n["content"][:200] if len(n["content"]) > 200 else n["content"]

        lines.append(
            f"""- ã‚¿ã‚¤ãƒˆãƒ«: {n['title']}
- æ—¥ä»˜: {date_str}
- ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆ: {n['sentiment'] or 'ä¸æ˜'}
- å†…å®¹: {content_preview}{'...' if len(n['content']) > 200 else ''}
- URL: {n['url'] or '(URLãªã—)'}
"""
        )

    return "\n".join(lines)
```

**Step 3: Create empty __init__.py**

```bash
touch scripts/lib/__init__.py
```

**Step 4: Verify Python syntax**

```bash
python3 -m py_compile scripts/lib/news_fetcher.py
```

Expected: No errors

**Step 5: Commit**

```bash
git add scripts/lib/
git commit -m "feat: add shared news fetching module for Python scripts"
```

---

## Task 2: Integrate News into Purchase Recommendations Script

**Files:**
- Modify: `scripts/github-actions/generate_purchase_recommendations.py`

**Step 1: Import news fetcher module**

Add at the top of the file (after existing imports):

```python
# Add to imports section
import sys
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))
from lib.news_fetcher import get_related_news, format_news_for_prompt
```

**Step 2: Update generate_recommendation function**

Modify the `generate_recommendation` function to accept news parameter and update the prompt:

Replace line 106 `def generate_recommendation(stock, prediction, recent_prices):` with:

```python
def generate_recommendation(stock, prediction, recent_prices, related_news=None):
    """OpenAI APIã‚’ä½¿ã£ã¦è³¼å…¥åˆ¤æ–­ã‚’ç”Ÿæˆ"""

    # ãƒ‹ãƒ¥ãƒ¼ã‚¹æƒ…å ±ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
    news_context = ""
    if related_news:
        news_context = f"""

ã€æœ€æ–°ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹æƒ…å ±ã€‘
{format_news_for_prompt(related_news)}
"""

    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰
    prompt = f"""ã‚ãªãŸã¯æŠ•è³‡åˆå¿ƒè€…å‘ã‘ã®AIã‚³ãƒ¼ãƒã§ã™ã€‚
ä»¥ä¸‹ã®éŠ˜æŸ„ã«ã¤ã„ã¦ã€è³¼å…¥åˆ¤æ–­ã‚’ã—ã¦ãã ã•ã„ã€‚

ã€éŠ˜æŸ„æƒ…å ±ã€‘
- åå‰: {stock['name']}
- ãƒ†ã‚£ãƒƒã‚«ãƒ¼ã‚³ãƒ¼ãƒ‰: {stock['tickerCode']}
- ã‚»ã‚¯ã‚¿ãƒ¼: {stock['sector'] or 'ä¸æ˜'}
- ç¾åœ¨ä¾¡æ ¼: {stock['currentPrice'] or 'ä¸æ˜'}å††

ã€äºˆæ¸¬æƒ…å ±ã€‘
- çŸ­æœŸäºˆæ¸¬: {prediction.get('shortTerm', 'ä¸æ˜')}
- ä¸­æœŸäºˆæ¸¬: {prediction.get('mediumTerm', 'ä¸æ˜')}
- é•·æœŸäºˆæ¸¬: {prediction.get('longTerm', 'ä¸æ˜')}

ã€æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ã€‘
ç›´è¿‘30æ—¥ã®çµ‚å€¤: {len(recent_prices)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚ã‚Š
{news_context}
ã€å›ç­”å½¢å¼ã€‘
ä»¥ä¸‹ã®JSONå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚JSONä»¥å¤–ã®ãƒ†ã‚­ã‚¹ãƒˆã¯å«ã‚ãªã„ã§ãã ã•ã„ã€‚

{{
  "recommendation": "buy" | "hold" | "pass",
  "confidence": 0.0ã‹ã‚‰1.0ã®æ•°å€¤ï¼ˆå°æ•°ç‚¹2æ¡ï¼‰,
  "reason": "åˆå¿ƒè€…ã«åˆ†ã‹ã‚Šã‚„ã™ã„è¨€è‘‰ã§1-2æ–‡ã®ç†ç”±ï¼ˆãƒ‹ãƒ¥ãƒ¼ã‚¹æƒ…å ±ãŒã‚ã‚Œã°å‚è€ƒã«ã™ã‚‹ï¼‰",
  "recommendedQuantity": 100æ ªå˜ä½ã®æ•´æ•°ï¼ˆbuyã®å ´åˆã®ã¿ã€ãã‚Œä»¥å¤–ã¯nullï¼‰,
  "recommendedPrice": ç›®å®‰ä¾¡æ ¼ã®æ•´æ•°ï¼ˆbuyã®å ´åˆã®ã¿ã€ãã‚Œä»¥å¤–ã¯nullï¼‰,
  "estimatedAmount": å¿…è¦é‡‘é¡ã®æ•´æ•°ï¼ˆbuyã®å ´åˆã®ã¿ã€ãã‚Œä»¥å¤–ã¯nullï¼‰,
  "caution": "æ³¨æ„ç‚¹ã‚’1-2æ–‡"
}}

ã€åˆ¶ç´„ã€‘
- æä¾›ã•ã‚ŒãŸãƒ‹ãƒ¥ãƒ¼ã‚¹æƒ…å ±ã‚’å‚è€ƒã«ã—ã¦ãã ã•ã„
- ãƒ‹ãƒ¥ãƒ¼ã‚¹ã«ãªã„æƒ…å ±ã¯æ¨æ¸¬ã‚„å‰µä½œã‚’ã—ãªã„ã§ãã ã•ã„
- å°‚é–€ç”¨èªã¯ä½¿ã‚ãªã„ï¼ˆROEã€PERã€æ ªä¾¡åç›Šç‡ãªã©ã¯ä½¿ç”¨ç¦æ­¢ï¼‰
- ã€Œæˆé•·æ€§ã€ã€Œå®‰å®šæ€§ã€ã€Œå‰²å®‰ã€ã®ã‚ˆã†ãªå¹³æ˜“ãªè¨€è‘‰ã‚’ä½¿ã†
- ç†ç”±ã¨æ³¨æ„ç‚¹ã¯ã€ä¸­å­¦ç”Ÿã§ã‚‚ç†è§£ã§ãã‚‹è¡¨ç¾ã«ã™ã‚‹
- recommendationãŒ"buy"ã®å ´åˆã®ã¿ã€recommendedQuantityã€recommendedPriceã€estimatedAmountã‚’è¨­å®š
- recommendationãŒ"hold"ã¾ãŸã¯"pass"ã®å ´åˆã€ã“ã‚Œã‚‰ã¯nullã«ã™ã‚‹
"""
```

**Step 3: Update main loop to fetch news**

Modify the main function's processing loop (around line 276):

```python
def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("=== Starting Purchase Recommendation Generation ===")
    print(f"Time: {datetime.now(timezone.utc).isoformat()}")

    # OpenAI APIã‚­ãƒ¼ã®ç¢ºèª
    if not os.getenv("OPENAI_API_KEY"):
        print("Error: OPENAI_API_KEY environment variable not set")
        sys.exit(1)

    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š
    conn = psycopg2.connect(DATABASE_URL)

    try:
        # ã‚¦ã‚©ãƒƒãƒãƒªã‚¹ãƒˆå–å¾—
        stocks = get_watchlist_stocks()

        if not stocks:
            print("No stocks in watchlist. Exiting.")
            sys.exit(0)

        # é–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’ä¸€æ‹¬å–å¾—
        ticker_codes = [s['tickerCode'] for s in stocks]
        sectors = list(set([s['sector'] for s in stocks if s['sector']]))

        print(f"Fetching related news for {len(ticker_codes)} stocks...")
        all_news = get_related_news(
            conn=conn,
            ticker_codes=ticker_codes,
            sectors=sectors,
            limit=20,  # è³¼å…¥åˆ¤æ–­ã¯å¤šã‚ã«å–å¾—
            days_ago=7,
        )
        print(f"Found {len(all_news)} related news articles")

        success_count = 0
        error_count = 0

        for stock in stocks:
            print(f"\n--- Processing: {stock['name']} ({stock['tickerCode']}) ---")

            # ã“ã®éŠ˜æŸ„ã«é–¢é€£ã™ã‚‹ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            stock_news = [
                n for n in all_news
                if (stock['tickerCode'] in n['content'] or
                    stock['tickerCode'].replace('.T', '') in n['content'] or
                    n['sector'] == stock['sector'])
            ][:5]  # æœ€å¤§5ä»¶

            print(f"Found {len(stock_news)} news for this stock")

            # äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿å–å¾—
            prediction = get_stock_prediction(stock['id'])

            # ç›´è¿‘ä¾¡æ ¼å–å¾—
            recent_prices = get_recent_prices(stock['tickerCode'])

            # è³¼å…¥åˆ¤æ–­ç”Ÿæˆï¼ˆãƒ‹ãƒ¥ãƒ¼ã‚¹ä»˜ãï¼‰
            recommendation = generate_recommendation(stock, prediction, recent_prices, stock_news)

            if not recommendation:
                print(f"âŒ Failed to generate recommendation for {stock['name']}")
                error_count += 1
                continue

            print(f"Generated recommendation: {recommendation['recommendation']}")
            print(f"Confidence: {recommendation['confidence']}")
            print(f"Reason: {recommendation['reason']}")

            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜
            if save_recommendation(stock['id'], recommendation):
                success_count += 1
            else:
                error_count += 1

        print(f"\n=== Summary ===")
        print(f"Total stocks processed: {len(stocks)}")
        print(f"Success: {success_count}")
        print(f"Errors: {error_count}")

        if error_count > 0:
            sys.exit(1)

    finally:
        conn.close()
```

**Step 4: Test locally with development database**

```bash
DATABASE_URL="postgresql://kouheikameyama@localhost:5432/stock_buddy" \
OPENAI_API_KEY="$OPENAI_API_KEY" \
python3 scripts/github-actions/generate_purchase_recommendations.py
```

Expected: Script runs and includes news in prompts

**Step 5: Commit**

```bash
git add scripts/github-actions/generate_purchase_recommendations.py
git commit -m "feat: integrate news RAG into purchase recommendations"
```

---

## Task 3: Integrate News into Portfolio Analysis Script

**Files:**
- Modify: `scripts/github-actions/generate_portfolio_analysis.py`

**Step 1: Import news fetcher module**

Add at the top of the file (after existing imports):

```python
# Add to imports section
import sys
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))
from lib.news_fetcher import get_related_news, format_news_for_prompt
```

**Step 2: Update generate_portfolio_analysis function**

Modify the `generate_portfolio_analysis` function to accept news parameter:

Replace line 99 `def generate_portfolio_analysis(stock, recent_prices):` with:

```python
def generate_portfolio_analysis(stock, recent_prices, related_news=None):
    """OpenAI APIã‚’ä½¿ã£ã¦ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªåˆ†æã‚’ç”Ÿæˆ"""

    average_price = float(stock['averagePurchasePrice'])
    current_price = float(stock['currentPrice']) if stock['currentPrice'] else None
    quantity = stock['quantity']

    profit, profit_percent = calculate_profit_loss(average_price, current_price, quantity)

    # ãƒ‹ãƒ¥ãƒ¼ã‚¹æƒ…å ±ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
    news_context = ""
    if related_news:
        news_context = f"""

ã€æœ€æ–°ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹æƒ…å ±ã€‘
{format_news_for_prompt(related_news)}
"""

    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰
    prompt = f"""ã‚ãªãŸã¯æŠ•è³‡åˆå¿ƒè€…å‘ã‘ã®AIã‚³ãƒ¼ãƒã§ã™ã€‚
ä»¥ä¸‹ã®ä¿æœ‰éŠ˜æŸ„ã«ã¤ã„ã¦ã€å£²è²·åˆ¤æ–­ã‚’ã—ã¦ãã ã•ã„ã€‚

ã€éŠ˜æŸ„æƒ…å ±ã€‘
- åå‰: {stock['name']}
- ãƒ†ã‚£ãƒƒã‚«ãƒ¼ã‚³ãƒ¼ãƒ‰: {stock['tickerCode']}
- ã‚»ã‚¯ã‚¿ãƒ¼: {stock['sector'] or 'ä¸æ˜'}
- ä¿æœ‰æ•°é‡: {quantity}æ ª
- å¹³å‡å–å¾—å˜ä¾¡: {average_price}å††
- ç¾åœ¨ä¾¡æ ¼: {current_price or 'ä¸æ˜'}å††
- æç›Š: {f'{profit:,.0f}å†† ({profit_percent:+.2f}%)' if profit is not None else 'ä¸æ˜'}

ã€æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ã€‘
ç›´è¿‘30æ—¥ã®çµ‚å€¤: {len(recent_prices)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚ã‚Š
{news_context}
ã€å›ç­”å½¢å¼ã€‘
ä»¥ä¸‹ã®JSONå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚JSONä»¥å¤–ã®ãƒ†ã‚­ã‚¹ãƒˆã¯å«ã‚ãªã„ã§ãã ã•ã„ã€‚

{{
  "shortTerm": "çŸ­æœŸäºˆæ¸¬ï¼ˆä»Šé€±ï¼‰ã®åˆ†æçµæœã‚’åˆå¿ƒè€…ã«åˆ†ã‹ã‚Šã‚„ã™ã2-3æ–‡ã§ï¼ˆãƒ‹ãƒ¥ãƒ¼ã‚¹æƒ…å ±ãŒã‚ã‚Œã°å‚è€ƒã«ã™ã‚‹ï¼‰",
  "mediumTerm": "ä¸­æœŸäºˆæ¸¬ï¼ˆä»Šæœˆï¼‰ã®åˆ†æçµæœã‚’åˆå¿ƒè€…ã«åˆ†ã‹ã‚Šã‚„ã™ã2-3æ–‡ã§ï¼ˆãƒ‹ãƒ¥ãƒ¼ã‚¹æƒ…å ±ãŒã‚ã‚Œã°å‚è€ƒã«ã™ã‚‹ï¼‰",
  "longTerm": "é•·æœŸäºˆæ¸¬ï¼ˆä»Šå¾Œ3ãƒ¶æœˆï¼‰ã®åˆ†æçµæœã‚’åˆå¿ƒè€…ã«åˆ†ã‹ã‚Šã‚„ã™ã2-3æ–‡ã§ï¼ˆãƒ‹ãƒ¥ãƒ¼ã‚¹æƒ…å ±ãŒã‚ã‚Œã°å‚è€ƒã«ã™ã‚‹ï¼‰"
}}

ã€åˆ¤æ–­ã®æŒ‡é‡ã€‘
- æä¾›ã•ã‚ŒãŸãƒ‹ãƒ¥ãƒ¼ã‚¹æƒ…å ±ã‚’å‚è€ƒã«ã—ã¦ãã ã•ã„
- ãƒ‹ãƒ¥ãƒ¼ã‚¹ã«ãªã„æƒ…å ±ã¯æ¨æ¸¬ã‚„å‰µä½œã‚’ã—ãªã„ã§ãã ã•ã„
- shortTerm: ã€Œå£²ã‚Šæ™‚ã€ã€Œä¿æŒã€ã€Œè²·ã„å¢—ã—æ™‚ã€ã®ã„ãšã‚Œã‹ã®åˆ¤æ–­ã‚’å«ã‚ã‚‹
- mediumTerm: ä»Šæœˆã®è¦‹é€šã—ã¨æ¨å¥¨è¡Œå‹•ã‚’å«ã‚ã‚‹
- longTerm: ä»Šå¾Œ3ãƒ¶æœˆã®æˆé•·æ€§ã¨æŠ•è³‡ç¶™ç¶šã®åˆ¤æ–­ã‚’å«ã‚ã‚‹
- å°‚é–€ç”¨èªã¯ä½¿ã‚ãªã„ï¼ˆROEã€PERã€æ ªä¾¡åç›Šç‡ãªã©ã¯ä½¿ç”¨ç¦æ­¢ï¼‰
- ã€Œæˆé•·æ€§ã€ã€Œå®‰å®šæ€§ã€ã€Œå‰²å®‰ã€ã€Œå‰²é«˜ã€ã®ã‚ˆã†ãªå¹³æ˜“ãªè¨€è‘‰ã‚’ä½¿ã†
- ä¸­å­¦ç”Ÿã§ã‚‚ç†è§£ã§ãã‚‹è¡¨ç¾ã«ã™ã‚‹
- æç›ŠçŠ¶æ³ã‚’è€ƒæ…®ã—ãŸå®Ÿè·µçš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’å«ã‚ã‚‹
"""
```

**Step 3: Update main loop to fetch news**

Modify the main function's processing loop (around line 232):

```python
def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("=== Starting Portfolio Analysis Generation ===")
    print(f"Time: {datetime.now(timezone.utc).isoformat()}")

    # OpenAI APIã‚­ãƒ¼ã®ç¢ºèª
    if not os.getenv("OPENAI_API_KEY"):
        print("Error: OPENAI_API_KEY environment variable not set")
        sys.exit(1)

    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š
    conn = psycopg2.connect(DATABASE_URL)

    try:
        # ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªå–å¾—
        stocks = get_portfolio_stocks()

        if not stocks:
            print("No stocks in portfolio. Exiting.")
            sys.exit(0)

        # é–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’ä¸€æ‹¬å–å¾—
        ticker_codes = [s['tickerCode'] for s in stocks]
        sectors = list(set([s['sector'] for s in stocks if s['sector']]))

        print(f"Fetching related news for {len(ticker_codes)} stocks...")
        all_news = get_related_news(
            conn=conn,
            ticker_codes=ticker_codes,
            sectors=sectors,
            limit=20,  # ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªåˆ†æã¯å¤šã‚ã«å–å¾—
            days_ago=7,
        )
        print(f"Found {len(all_news)} related news articles")

        success_count = 0
        error_count = 0

        for stock in stocks:
            print(f"\n--- Processing: {stock['name']} ({stock['tickerCode']}) ---")

            # ã“ã®éŠ˜æŸ„ã«é–¢é€£ã™ã‚‹ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            stock_news = [
                n for n in all_news
                if (stock['tickerCode'] in n['content'] or
                    stock['tickerCode'].replace('.T', '') in n['content'] or
                    n['sector'] == stock['sector'])
            ][:5]  # æœ€å¤§5ä»¶

            print(f"Found {len(stock_news)} news for this stock")

            # ç›´è¿‘ä¾¡æ ¼å–å¾—
            recent_prices = get_recent_prices(stock['tickerCode'])

            # ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªåˆ†æç”Ÿæˆï¼ˆãƒ‹ãƒ¥ãƒ¼ã‚¹ä»˜ãï¼‰
            analysis = generate_portfolio_analysis(stock, recent_prices, stock_news)

            if not analysis:
                print(f"âŒ Failed to generate analysis for {stock['name']}")
                error_count += 1
                continue

            print(f"Generated analysis:")
            print(f"Short-term: {analysis['shortTerm'][:50]}...")
            print(f"Medium-term: {analysis['mediumTerm'][:50]}...")
            print(f"Long-term: {analysis['longTerm'][:50]}...")

            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜
            if save_portfolio_analysis(stock['id'], analysis):
                success_count += 1
            else:
                error_count += 1

        print(f"\n=== Summary ===")
        print(f"Total stocks processed: {len(stocks)}")
        print(f"Success: {success_count}")
        print(f"Errors: {error_count}")

        if error_count > 0:
            sys.exit(1)

    finally:
        conn.close()
```

**Step 4: Test locally with development database**

```bash
DATABASE_URL="postgresql://kouheikameyama@localhost:5432/stock_buddy" \
OPENAI_API_KEY="$OPENAI_API_KEY" \
python3 scripts/github-actions/generate_portfolio_analysis.py
```

Expected: Script runs and includes news in prompts

**Step 5: Commit**

```bash
git add scripts/github-actions/generate_portfolio_analysis.py
git commit -m "feat: integrate news RAG into portfolio analysis"
```

---

## Task 4: Integrate News into Stock Predictions Script

**Files:**
- Modify: `scripts/analysis/generate_stock_predictions.py`

**Step 1: Import news fetcher module**

Add at the top of the file (after existing imports):

```python
# Add to imports section
import sys
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))
from lib.news_fetcher import get_related_news, format_news_for_prompt
```

**Step 2: Update generate_ai_prediction function**

Modify the `generate_ai_prediction` function to accept news parameter:

Replace line 91 `def generate_ai_prediction(stock, baseline, scores):` with:

```python
def generate_ai_prediction(stock, baseline, scores, related_news=None):
    """AIã§äºˆæ¸¬ã‚’ç”Ÿæˆ"""

    trend_labels = {"up": "ä¸Šæ˜‡", "neutral": "æ¨ªã°ã„", "down": "ä¸‹é™"}

    # ãƒ‹ãƒ¥ãƒ¼ã‚¹æƒ…å ±ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
    news_context = ""
    if related_news:
        news_context = f"""

ã€æœ€æ–°ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹æƒ…å ±ã€‘
{format_news_for_prompt(related_news)}
"""

    prompt = f"""ã‚ãªãŸã¯æ ªå¼æŠ•è³‡ã®åˆå¿ƒè€…å‘ã‘ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼ã§ã™ã€‚
ä»¥ä¸‹ã®éŠ˜æŸ„ã«ã¤ã„ã¦ã€ä»Šå¾Œã®å‹•å‘äºˆæ¸¬ã¨ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

ã€éŠ˜æŸ„æƒ…å ±ã€‘
åç§°: {stock['name']}
ãƒ†ã‚£ãƒƒã‚«ãƒ¼: {stock['ticker_code']}
ã‚»ã‚¯ã‚¿ãƒ¼: {stock['sector'] or 'ä¸æ˜'}
ç¾åœ¨ä¾¡æ ¼: {baseline['current_price']:.2f}å††

ã€éå»ã®ãƒˆãƒ¬ãƒ³ãƒ‰ã€‘
- 1é€±é–“: {trend_labels[baseline['weekly_trend']]}
- 1ãƒ¶æœˆ: {trend_labels[baseline['monthly_trend']]}
- 3ãƒ¶æœˆ: {trend_labels[baseline['quarterly_trend']]}

ã€ã‚¹ã‚³ã‚¢ã€‘
- æˆé•·æ€§: {scores['growth']}/100
- å®‰å®šæ€§: {scores['stability']}/100
- é…å½“æ€§: {scores['dividend']}/100

ã€ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆä¾¡æ ¼å¤‰å‹•å¹…ï¼‰ã€‘
{baseline['volatility']:.2f}å††
{news_context}
---

ä»¥ä¸‹ã®å½¢å¼ã§JSONå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ï¼š

{{
  "shortTerm": {{
    "trend": "up" | "neutral" | "down",
    "priceLow": æ•°å€¤,
    "priceHigh": æ•°å€¤
  }},
  "midTerm": {{
    "trend": "up" | "neutral" | "down",
    "priceLow": æ•°å€¤,
    "priceHigh": æ•°å€¤
  }},
  "longTerm": {{
    "trend": "up" | "neutral" | "down",
    "priceLow": æ•°å€¤,
    "priceHigh": æ•°å€¤
  }},
  "recommendation": "buy" | "hold" | "sell",
  "advice": "åˆå¿ƒè€…å‘ã‘ã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹ï¼ˆ100æ–‡å­—ä»¥å†…ã€å„ªã—ã„è¨€è‘‰ã§ã€ãƒ‹ãƒ¥ãƒ¼ã‚¹æƒ…å ±ãŒã‚ã‚Œã°å‚è€ƒã«ã™ã‚‹ï¼‰",
  "confidence": 0.0ã€œ1.0ã®ä¿¡é ¼åº¦
}}

æ³¨æ„äº‹é …:
- æä¾›ã•ã‚ŒãŸãƒ‹ãƒ¥ãƒ¼ã‚¹æƒ…å ±ã‚’å‚è€ƒã«ã—ã¦ãã ã•ã„
- ãƒ‹ãƒ¥ãƒ¼ã‚¹ã«ãªã„æƒ…å ±ã¯æ¨æ¸¬ã‚„å‰µä½œã‚’ã—ãªã„ã§ãã ã•ã„
- ä¾¡æ ¼äºˆæ¸¬ã¯ç¾åœ¨ä¾¡æ ¼ã¨ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚’è€ƒæ…®ã—ãŸç¾å®Ÿçš„ãªç¯„å›²ã«ã™ã‚‹
- ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã¯å…·ä½“çš„ã§åˆ†ã‹ã‚Šã‚„ã™ã
- æ–­å®šçš„ãªè¡¨ç¾ã¯é¿ã‘ã€ã€Œã€œãŒæœŸå¾…ã§ãã¾ã™ã€ã€Œã€œã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€ãªã©æŸ”ã‚‰ã‹ã„è¡¨ç¾ã‚’ä½¿ã†
- æŠ•è³‡åˆ¤æ–­ã¯æœ€çµ‚çš„ã«ãƒ¦ãƒ¼ã‚¶ãƒ¼è‡ªèº«ãŒè¡Œã†ã“ã¨ã‚’å‰æã«ã™ã‚‹
"""
```

**Step 3: Update main loop to fetch news**

Modify the main function's processing loop (around line 236):

```python
def main():
    print("ğŸš€ Starting stock predictions generation...")

    if not DATABASE_URL:
        print("âŒ ERROR: DATABASE_URL not set")
        sys.exit(1)

    if not OPENAI_API_KEY:
        print("âŒ ERROR: OPENAI_API_KEY not set")
        sys.exit(1)

    conn = psycopg2.connect(DATABASE_URL)
    cur = conn.cursor(cursor_factory=psycopg2.extras.DictCursor)

    try:
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒä¿æœ‰/ã‚¦ã‚©ãƒƒãƒã—ã¦ã„ã‚‹éŠ˜æŸ„ã‚’å–å¾—
        cur.execute(
            """
            SELECT DISTINCT s.id, s."tickerCode", s.name, s.sector,
                   s."growthScore", s."stabilityScore", s."dividendScore"
            FROM "Stock" s
            INNER JOIN "UserStock" us ON s.id = us."stockId"
        """
        )

        stocks = cur.fetchall()
        total = len(stocks)

        if total == 0:
            print("âš ï¸  No stocks to analyze")
            return

        print(f"ğŸ“Š Processing {total} stocks...")

        # é–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’ä¸€æ‹¬å–å¾—
        ticker_codes = [s["tickerCode"] for s in stocks]
        sectors = list(set([s["sector"] for s in stocks if s["sector"]]))

        print(f"ğŸ“° Fetching related news for {len(ticker_codes)} stocks...")
        all_news = get_related_news(
            conn=conn,
            ticker_codes=ticker_codes,
            sectors=sectors,
            limit=30,  # äºˆæ¸¬ç”Ÿæˆã¯å¤šã‚ã«å–å¾—
            days_ago=7,
        )
        print(f"Found {len(all_news)} related news articles")

        success = 0
        failed = 0

        for i, stock in enumerate(stocks, 1):
            stock_dict = {
                "id": stock["id"],
                "ticker_code": stock["tickerCode"],
                "name": stock["name"],
                "sector": stock["sector"],
            }

            scores = {
                "growth": stock["growthScore"] or 50,
                "stability": stock["stabilityScore"] or 50,
                "dividend": stock["dividendScore"] or 50,
            }

            try:
                print(
                    f"[{i}/{total}] Processing {stock_dict['name']} ({stock_dict['ticker_code']})..."
                )

                # ã“ã®éŠ˜æŸ„ã«é–¢é€£ã™ã‚‹ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                stock_news = [
                    n for n in all_news
                    if (stock_dict['ticker_code'] in n['content'] or
                        stock_dict['ticker_code'].replace('.T', '') in n['content'] or
                        n['sector'] == stock_dict['sector'])
                ][:5]  # æœ€å¤§5ä»¶

                print(f"  ğŸ“° Found {len(stock_news)} news for this stock")

                # 1. åŸºç¤ãƒ‡ãƒ¼ã‚¿è¨ˆç®—
                baseline = get_baseline_data(cur, stock_dict["id"])

                if not baseline:
                    print(f"  âš ï¸  No price data available, skipping...")
                    failed += 1
                    continue

                # 2. AIäºˆæ¸¬ç”Ÿæˆï¼ˆãƒ‹ãƒ¥ãƒ¼ã‚¹ä»˜ãï¼‰
                prediction = generate_ai_prediction(stock_dict, baseline, scores, stock_news)

                # 3. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
                save_prediction(cur, stock_dict["id"], prediction)

                conn.commit()
                success += 1
                print(f"  âœ… Saved (recommendation: {prediction['recommendation']})")

            except Exception as e:
                print(f"  âŒ Error: {e}")
                conn.rollback()
                failed += 1

        print(f"\nğŸ‰ Completed!")
        print(f"  âœ… Success: {success}")
        print(f"  âŒ Failed: {failed}")
        print(f"  ğŸ“Š Total: {total}")

        if failed > 0 and success == 0:
            sys.exit(1)

    finally:
        cur.close()
        conn.close()
```

**Step 4: Test locally with development database**

```bash
DATABASE_URL="postgresql://kouheikameyama@localhost:5432/stock_buddy" \
OPENAI_API_KEY="$OPENAI_API_KEY" \
python3 scripts/analysis/generate_stock_predictions.py
```

Expected: Script runs and includes news in prompts

**Step 5: Commit**

```bash
git add scripts/analysis/generate_stock_predictions.py
git commit -m "feat: integrate news RAG into stock predictions"
```

---

## Task 5: Test All Scripts with Production Database (Dry Run)

**Files:**
- Test: All three modified scripts

**Step 1: Test purchase recommendations with production DB**

```bash
DATABASE_URL="postgresql://postgres:uQTJVhgdFjPKavBZwbjjQFAsKQbYMuMx@mainline.proxy.rlwy.net:51383/railway" \
OPENAI_API_KEY="$OPENAI_API_KEY" \
python3 scripts/github-actions/generate_purchase_recommendations.py
```

Expected: Script completes successfully with news integration

**Step 2: Test portfolio analysis with production DB**

```bash
DATABASE_URL="postgresql://postgres:uQTJVhgdFjPKavBZwbjjQFAsKQbYMuMx@mainline.proxy.rlwy.net:51383/railway" \
OPENAI_API_KEY="$OPENAI_API_KEY" \
python3 scripts/github-actions/generate_portfolio_analysis.py
```

Expected: Script completes successfully with news integration

**Step 3: Test stock predictions with production DB**

```bash
DATABASE_URL="postgresql://postgres:uQTJVhgdFjPKavBZwbjjQFAsKQbYMuMx@mainline.proxy.rlwy.net:51383/railway" \
OPENAI_API_KEY="$OPENAI_API_KEY" \
python3 scripts/analysis/generate_stock_predictions.py
```

Expected: Script completes successfully with news integration

**Step 4: Verify news are being used in results**

Check database to ensure generated analyses reference recent news:

```bash
PGPASSWORD="uQTJVhgdFjPKavBZwbjjQFAsKQbYMuMx" psql -h mainline.proxy.rlwy.net -p 51383 -U postgres -d railway -c "SELECT reason FROM \"PurchaseRecommendation\" ORDER BY date DESC LIMIT 3;"
```

Expected: Recent recommendations should mention news-related context

**Step 5: Commit final changes**

```bash
git add .
git commit -m "test: verify news RAG integration in all analysis scripts"
```

---

## Task 6: Update Documentation

**Files:**
- Create: `docs/features/news-rag-python-scripts.md`

**Step 1: Create documentation file**

Create `docs/features/news-rag-python-scripts.md`:

```markdown
# News RAG Integration - Python Analysis Scripts

## æ¦‚è¦

Pythonåˆ†æã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆè³¼å…¥åˆ¤æ–­ã€ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªåˆ†æã€éŠ˜æŸ„äºˆæ¸¬ï¼‰ã«MarketNewsãƒ†ãƒ¼ãƒ–ãƒ«ã®æœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’çµ±åˆã—ã¾ã—ãŸã€‚

## çµ±åˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ

### 1. è³¼å…¥åˆ¤æ–­ç”Ÿæˆï¼ˆgenerate_purchase_recommendations.pyï¼‰

**å¯¾è±¡**: ã‚¦ã‚©ãƒƒãƒãƒªã‚¹ãƒˆéŠ˜æŸ„

**ãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾—**:
- éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰å„ªå…ˆæ¤œç´¢
- ã‚»ã‚¯ã‚¿ãƒ¼æ¤œç´¢ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
- ç›´è¿‘7æ—¥é–“ã€æœ€å¤§20ä»¶

**ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¿½åŠ **:
```
ã€æœ€æ–°ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹æƒ…å ±ã€‘
- ã‚¿ã‚¤ãƒˆãƒ«: ...
- æ—¥ä»˜: ...
- ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆ: ...
- å†…å®¹: ...
```

**åŠ¹æœ**:
- è©±é¡Œã®éŠ˜æŸ„ã‚’å„ªå…ˆæ¨å¥¨
- ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ™ãƒ¼ã‚¹ã®è³¼å…¥ç†ç”±
- å¸‚å ´ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’åæ˜ 

### 2. ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªåˆ†æï¼ˆgenerate_portfolio_analysis.pyï¼‰

**å¯¾è±¡**: ä¿æœ‰éŠ˜æŸ„

**ãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾—**:
- ä¿æœ‰éŠ˜æŸ„é–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹
- ç›´è¿‘7æ—¥é–“ã€æœ€å¤§20ä»¶

**ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¿½åŠ **:
- çŸ­æœŸãƒ»ä¸­æœŸãƒ»é•·æœŸåˆ†æã«ãƒ‹ãƒ¥ãƒ¼ã‚¹æƒ…å ±ã‚’åæ˜ 
- å£²è²·åˆ¤æ–­ã®æ ¹æ‹ ã«ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’æ´»ç”¨

**åŠ¹æœ**:
- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æƒ…å ±ã«åŸºã¥ãåˆ†æ
- ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ™ãƒ¼ã‚¹ã®å£²è²·åˆ¤æ–­
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ä¿æœ‰éŠ˜æŸ„ã«æœ€é©åŒ–

### 3. éŠ˜æŸ„äºˆæ¸¬ç”Ÿæˆï¼ˆgenerate_stock_predictions.pyï¼‰

**å¯¾è±¡**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒä¿æœ‰/ã‚¦ã‚©ãƒƒãƒã—ã¦ã„ã‚‹éŠ˜æŸ„

**ãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾—**:
- äºˆæ¸¬å¯¾è±¡éŠ˜æŸ„é–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹
- ç›´è¿‘7æ—¥é–“ã€æœ€å¤§30ä»¶

**ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¿½åŠ **:
- ãƒˆãƒ¬ãƒ³ãƒ‰äºˆæ¸¬ã«ãƒ‹ãƒ¥ãƒ¼ã‚¹æƒ…å ±ã‚’åæ˜ 
- ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã«ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’æ´»ç”¨

**åŠ¹æœ**:
- ã‚ˆã‚Šç²¾åº¦ã®é«˜ã„äºˆæ¸¬
- å¸‚å ´å‹•å‘ã‚’åæ˜ ã—ãŸã‚¢ãƒ‰ãƒã‚¤ã‚¹
- ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ™ãƒ¼ã‚¹ã®æŠ•è³‡åˆ¤æ–­

## å…±é€šãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

### scripts/lib/news_fetcher.py

**é–¢æ•°**:
- `get_related_news()`: ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ã§ãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾—
- `format_news_for_prompt()`: AIç”¨ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ

**æ¤œç´¢æ–¹å¼**:
1. éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰æ¤œç´¢ï¼ˆcontent LIKE '%7203%'ï¼‰
2. ã‚»ã‚¯ã‚¿ãƒ¼æ¤œç´¢ï¼ˆsector IN (...)ï¼‰

**å–å¾—ç¯„å›²**:
- æœŸé–“: ç›´è¿‘7æ—¥é–“
- ä»¶æ•°: ã‚¹ã‚¯ãƒªãƒ—ãƒˆã”ã¨ã«èª¿æ•´å¯èƒ½
- ã‚½ãƒ¼ãƒˆ: publishedAt DESC

## ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³å¯¾ç­–

### ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆåˆ¶ç´„

å…¨ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ä»¥ä¸‹ã‚’è¿½åŠ ï¼š

```
- æä¾›ã•ã‚ŒãŸãƒ‹ãƒ¥ãƒ¼ã‚¹æƒ…å ±ã‚’å‚è€ƒã«ã—ã¦ãã ã•ã„
- ãƒ‹ãƒ¥ãƒ¼ã‚¹ã«ãªã„æƒ…å ±ã¯æ¨æ¸¬ã‚„å‰µä½œã‚’ã—ãªã„ã§ãã ã•ã„
- å°‚é–€ç”¨èªã¯ä½¿ã‚ãªã„
- åˆå¿ƒè€…ã«åˆ†ã‹ã‚Šã‚„ã™ã„è¨€è‘‰ã‚’ä½¿ã†
```

### ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°

```python
try:
    news = get_related_news(...)
except:
    news = []  # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ç©ºé…åˆ—ï¼ˆåˆ†æã¯ç¶™ç¶šï¼‰
```

ãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾—å¤±æ•—æ™‚ã‚‚åˆ†æã¯ç¶™ç¶šå¯èƒ½ã€‚

## ãƒ†ã‚¹ãƒˆæ–¹æ³•

### ãƒ­ãƒ¼ã‚«ãƒ«ãƒ†ã‚¹ãƒˆ

```bash
# è³¼å…¥åˆ¤æ–­
DATABASE_URL="postgresql://..." \
OPENAI_API_KEY="..." \
python3 scripts/github-actions/generate_purchase_recommendations.py

# ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªåˆ†æ
DATABASE_URL="postgresql://..." \
OPENAI_API_KEY="..." \
python3 scripts/github-actions/generate_portfolio_analysis.py

# éŠ˜æŸ„äºˆæ¸¬
DATABASE_URL="postgresql://..." \
OPENAI_API_KEY="..." \
python3 scripts/analysis/generate_stock_predictions.py
```

### çµæœç¢ºèª

```sql
-- è³¼å…¥åˆ¤æ–­
SELECT reason FROM "PurchaseRecommendation"
ORDER BY date DESC LIMIT 3;

-- ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªåˆ†æ
SELECT "shortTerm" FROM "PortfolioStock"
WHERE "lastAnalysis" IS NOT NULL
LIMIT 3;

-- éŠ˜æŸ„äºˆæ¸¬
SELECT advice FROM "StockAnalysis"
ORDER BY "analyzedAt" DESC LIMIT 3;
```

ãƒ‹ãƒ¥ãƒ¼ã‚¹é–¢é€£ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆä¼æ¥­åã€ãƒ‹ãƒ¥ãƒ¼ã‚¹å†…å®¹ãªã©ï¼‰ãŒå«ã¾ã‚Œã¦ã„ã‚Œã°OKã€‚

## ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹

### ã‚¯ã‚¨ãƒªæœ€é©åŒ–

- ãƒãƒƒãƒå–å¾—: å…¨éŠ˜æŸ„ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’ä¸€æ‹¬å–å¾—
- ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°: Pythonã§éŠ˜æŸ„ã”ã¨ã«ãƒ•ã‚£ãƒ«ã‚¿
- ä»¶æ•°åˆ¶é™: éŠ˜æŸ„ã‚ãŸã‚Šæœ€å¤§5ä»¶

### ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“

- ãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾—: 100msä»¥å†…
- åˆ†æå…¨ä½“: æ—¢å­˜å‡¦ç† + 100msç¨‹åº¦

## ã‚³ã‚¹ãƒˆå½±éŸ¿

### OpenAI APIãƒˆãƒ¼ã‚¯ãƒ³æ¶ˆè²»å¢—åŠ 

- **è³¼å…¥åˆ¤æ–­**: +500ãƒˆãƒ¼ã‚¯ãƒ³/éŠ˜æŸ„
- **ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªåˆ†æ**: +500ãƒˆãƒ¼ã‚¯ãƒ³/éŠ˜æŸ„
- **éŠ˜æŸ„äºˆæ¸¬**: +500ãƒˆãƒ¼ã‚¯ãƒ³/éŠ˜æŸ„

### æœˆé–“è¿½åŠ ã‚³ã‚¹ãƒˆè¦‹ç©ã‚‚ã‚Š

- 1æ—¥ã‚ãŸã‚Š: ç´„$0.05
- æœˆé–“: ç´„$1.50

æ—¢å­˜ã‚³ã‚¹ãƒˆã«å¯¾ã—ã¦ç´„10-15%ã®å¢—åŠ ã€‚

## å°†æ¥ã®æ‹¡å¼µ

- ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆã‚¹ã‚³ã‚¢ã«ã‚ˆã‚‹é‡ã¿ä»˜ã‘
- ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®ã‚«ãƒ†ã‚´ãƒªåˆ†é¡
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã”ã¨ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹å„ªå…ˆåº¦è¨­å®š
- ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ™ãƒ¼ã‚¹ã®ã‚¢ãƒ©ãƒ¼ãƒˆæ©Ÿèƒ½
```

**Step 2: Commit documentation**

```bash
git add docs/features/news-rag-python-scripts.md
git commit -m "docs: add news RAG integration documentation for Python scripts"
```

---

## Task 7: Create Pull Request

**Step 1: Push branch to remote**

```bash
git push origin main
```

**Step 2: Verify all changes**

```bash
git log --oneline -10
```

Expected: All commits are present

**Step 3: Final verification**

Review changes:
- âœ… Shared news fetcher module created
- âœ… Purchase recommendations script updated
- âœ… Portfolio analysis script updated
- âœ… Stock predictions script updated
- âœ… All scripts tested with production DB
- âœ… Documentation created

---

## Summary

This plan integrates MarketNews RAG into three Python analysis scripts:

1. **Purchase Recommendations** - Watchlist stocks buying decisions
2. **Portfolio Analysis** - Held stocks sell/hold/buy-more analysis
3. **Stock Predictions** - Trend predictions with news context

**Key Benefits:**
- AI analyses now reference latest market news
- More accurate and timely recommendations
- News-based reasoning improves user trust
- Minimal performance impact (~100ms per script)

**Cost Impact:**
- +500 tokens per stock analysis
- ~$1.50/month additional cost

**Hallucination Prevention:**
- Explicit prompt constraints
- "Use only provided news" instruction
- Graceful error handling
